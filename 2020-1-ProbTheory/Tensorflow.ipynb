{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VI0owR4htDQv"
   },
   "source": [
    "# Introduction to Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NcA_ExQtDQw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2g-lHOOJ93zQ",
    "outputId": "3d211351-44d8-4240-e9b7-1608d090c30d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nwLvNiefQifF"
   },
   "source": [
    "# PART 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rpUi5WflQofz"
   },
   "source": [
    "## (a) Calculate log-likelihood function in the above problem using R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAHO3PJbUABr"
   },
   "source": [
    "```R\n",
    "library(tidyverse)\n",
    "\n",
    "mydata <- read.csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")\n",
    "head(mydata) # admit (y) : 0/1, gre, gpa, rank : 설명변수\n",
    "\n",
    "mymodel <- glm(admit ~ gre + gpa + rank, data = mydata, family = \"binomial\")\n",
    "summary(mymodel)\n",
    "\n",
    "## 1: 1 0 380 3.61 3\n",
    "z=-3.449548 + 0.002294*380 +0.777014 *3.61 -0.560031 *3\n",
    "p=1/(1+exp(-z))\n",
    "p # 확률 0.1895556\n",
    "\n",
    "## 3: 1 800 4.00 1\n",
    "z3=-3.449548 + 0.002294*800 +0.777014 *4.00 -0.560031 *1\n",
    "p3=1/(1+exp(-z3))\n",
    "p3 # 확률 0.7178207 \n",
    "\n",
    "predict(mymodel, type=\"response\") # 각각의 데이터에 대한 predict 값 \n",
    "\n",
    "# log likelihood\n",
    "pred <- cbind(mydata, predict(mymodel, type=\"response\"))\n",
    "pred <- as_tibble(pred) %>% rename(y=admit, ypred = \"predict(mymodel, type = \\\"response\\\")\", gre=gre, gpa=gpa, rank=rank)\n",
    "pred <- pred %>% mutate(loglike = -(y*log(ypred)+(1-y)*log(1-ypred)))\n",
    "sum(pred$loglike)/400\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![R1](https://user-images.githubusercontent.com/43749571/95837094-294d4380-0d7b-11eb-82a5-8b0566f74e15.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![R2](https://user-images.githubusercontent.com/43749571/95837097-29e5da00-0d7b-11eb-89d7-a42ab1bac298.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![R3](https://user-images.githubusercontent.com/43749571/95837099-2b170700-0d7b-11eb-86da-3a06306effaa.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICYL_f6IQthI"
   },
   "source": [
    "## (b) Calculate log-likelihood function in the above problem using tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cd_ka6cLT6KT"
   },
   "source": [
    "### Data 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCPAfESiRIhq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "999gkLcrRU7_",
    "outputId": "dfde70ec-f717-4ce3-f4a9-cd2467b14356"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkuIehVuSuOH"
   },
   "outputs": [],
   "source": [
    "mydata = mydata.to_numpy() # numpy 형태로 바꿔준다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9kVmbyYSUcP"
   },
   "outputs": [],
   "source": [
    "mydata_exp = mydata[:, 1:] # 설명변수 (x)\n",
    "mydata_rep = mydata[:, 0] # 반응변수 (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Qra7huK1STTL",
    "outputId": "8ceaf017-4eb7-4d42-cb68-1953b343d652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 3) (400,)\n"
     ]
    }
   ],
   "source": [
    "print(mydata_exp.shape, mydata_rep.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gczYkdKuRjIv"
   },
   "outputs": [],
   "source": [
    "m, n = mydata_exp.shape # (400, 3)\n",
    "mydata_exp_plus_bias = np.c_[np.ones((m, 1)), mydata_exp] # (400, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xjIU2Kw1WDAh",
    "outputId": "401127a3-0a14-497d-b7f3-5158fb68cfdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_mydata_exp_plus_bias = mydata_exp_plus_bias / mydata_exp_plus_bias.max(axis=0) # 0과 1 사이의 숫자로 scaling \n",
    "scaled_mydata_exp_plus_bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jU6lhnupUetF"
   },
   "source": [
    "### logistic regression with tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AqD4ozST3jE"
   },
   "outputs": [],
   "source": [
    "X = tf.constant(scaled_mydata_exp_plus_bias, dtype=tf.float32, name=\"X\") # (400, 4)\n",
    "y = tf.constant(mydata_rep.reshape(-1, 1), dtype=tf.float32, name=\"y\") # (400, 1)\n",
    "XT = tf.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P67ZhXi1U2B7"
   },
   "outputs": [],
   "source": [
    "beta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "5l1AxM21U7WL",
    "outputId": "20b31ee1-cd8b-4766-b3d0-0eb353ddc6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18242253]\n",
      " [ 0.3539362 ]\n",
      " [ 0.604179  ]\n",
      " [-0.43800795]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    beta_value = beta.eval()\n",
    "    \n",
    "print(beta_value) # beta0, beta1, beta2, beta3 (상수항, gre, gpa, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ww-4DFboVASi"
   },
   "outputs": [],
   "source": [
    "z = np.matmul(scaled_mydata_exp_plus_bias, beta_value) # X*beta\n",
    "predict = tf.sigmoid(z)  # y = 1 / (1 + exp(-z)) : 확률값으로 나오게 됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2CG_HMxbXyr"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_pred = predict.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7K-iCbVNaWp6"
   },
   "outputs": [],
   "source": [
    "myy = mydata_rep.reshape(-1, 1) # y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "q5iLg2b9VDw3",
    "outputId": "b597bd9b-82c9-4696-8c49-bb5346e50e5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f21000719e8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y_pred, myy, \"*\") # predict 값들이 어떤 분포를 보이고 있는지, 이 때의 실제 y값과의 관계는 어떠한지에 대한 비교 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "M1GTig8BcSqV",
    "outputId": "978df75d-5f46-4600-ef09-db4ce3e0abf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.82422534e-01],\n",
       "       [ 2.83148956e+02],\n",
       "       [ 2.41671610e+00],\n",
       "       [-1.75203180e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비교해 보아야 할 beta 값 \n",
    "b_beta_value = np.multiply(beta_value, mydata_exp_plus_bias.max(axis=0).reshape(-1,1))\n",
    "b_beta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7UHgyGKKTEBh",
    "outputId": "303e1040-4d5b-4c6b-fdcd-d72618771b34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7453664863257206"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log likelihood \n",
    "b_loglik = -np.mean(myy*np.log(y_pred) + (1-myy)*np.log(1-y_pred))\n",
    "b_loglik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cb1QV3-eQwV_"
   },
   "source": [
    "## (c) Calculate log-likelihood function in the above problem using tensorflow and mini batch learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0_EmFFBbjZsi"
   },
   "source": [
    "### Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdKElWitQ9Ac"
   },
   "outputs": [],
   "source": [
    "# 준비 \n",
    "n_epochs = 30000\n",
    "learning_rate = 0.005\n",
    "\n",
    "# 선언만 계속 해줌 : X, y, beta, mse \n",
    "X = tf.constant(scaled_mydata_exp_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(mydata_rep.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "beta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"beta\") # 왜 Variable? beta 바꿔가면서 cost function optimize 할 것이기 때문에 \n",
    "y_pred = tf.sigmoid(tf.matmul(X, beta, name=\"predictions\")) # 확률값 \n",
    "cost = -tf.reduce_mean(y*tf.log(y_pred) + (1-y)*tf.log(1-y_pred)) # binary cross entropy \n",
    "\n",
    "# beta_hat 는 \"cost function을 최소화\" 시키는 beta\n",
    "\n",
    "# optimum value를 찾는 계산기 만들기 = cost function를 최소화 시켜줘 !! \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "training_op = optimizer.minimize(cost) # beta <- beta -learning_rate*기울기 : 1 step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "QjIGm-OWjeLL",
    "outputId": "5557e1ae-a2cb-44bf-b303-921885222d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Cost = 0.68111175\n",
      "Epoch 1000 Cost = 0.6263726\n",
      "Epoch 2000 Cost = 0.61900747\n",
      "Epoch 3000 Cost = 0.6130547\n",
      "Epoch 4000 Cost = 0.60822463\n",
      "Epoch 5000 Cost = 0.6042875\n",
      "Epoch 6000 Cost = 0.60106146\n",
      "Epoch 7000 Cost = 0.5984029\n",
      "Epoch 8000 Cost = 0.5961983\n",
      "Epoch 9000 Cost = 0.5943582\n",
      "Epoch 10000 Cost = 0.59281164\n",
      "Epoch 11000 Cost = 0.59150255\n",
      "Epoch 12000 Cost = 0.5903859\n",
      "Epoch 13000 Cost = 0.5894263\n",
      "Epoch 14000 Cost = 0.58859503\n",
      "Epoch 15000 Cost = 0.5878693\n",
      "Epoch 16000 Cost = 0.5872305\n",
      "Epoch 17000 Cost = 0.5866638\n",
      "Epoch 18000 Cost = 0.58615714\n",
      "Epoch 19000 Cost = 0.5857007\n",
      "Epoch 20000 Cost = 0.5852865\n",
      "Epoch 21000 Cost = 0.584908\n",
      "Epoch 22000 Cost = 0.5845598\n",
      "Epoch 23000 Cost = 0.5842375\n",
      "Epoch 24000 Cost = 0.58393764\n",
      "Epoch 25000 Cost = 0.583657\n",
      "Epoch 26000 Cost = 0.58339316\n",
      "Epoch 27000 Cost = 0.5831441\n",
      "Epoch 28000 Cost = 0.582908\n",
      "Epoch 29000 Cost = 0.5826835\n",
      "[[-0.66179717]\n",
      " [ 1.3787856 ]\n",
      " [ 0.34281203]\n",
      " [-2.3480084 ]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() # beta (variable)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch\", epoch, \"Cost =\", cost.eval())\n",
    "        sess.run(training_op) # 1 step을 가시오. 한 바퀴 (1000번) 끝나면 나올 것 \n",
    "    best_beta = beta.eval() # beta값 계속 변하게 됨 \n",
    "print(best_beta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "qSa6Erlllh1v",
    "outputId": "82ada185-49f8-4d0c-f040-90d89f9ade5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.61797166e-01],\n",
       "       [ 1.10302849e+03],\n",
       "       [ 1.37124813e+00],\n",
       "       [-9.39203358e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비교해 보아야 할 beta 값 \n",
    "c1_beta_value = np.multiply(best_beta, mydata_exp_plus_bias.max(axis=0).reshape(-1,1))\n",
    "c1_beta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzoDdnnll1EJ"
   },
   "source": [
    "### Mini Batch Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAr03-TWlyze"
   },
   "outputs": [],
   "source": [
    "# placeholder : 상수처럼 쓰이는데, 항상 같은 데이터 쓰지 않고, for문 돌릴 때 마다 다른 데이터가 들어간다 \n",
    "X = tf.placeholder(tf.float32, shape=[None,n+1]) # 이전에는 constant, batch learning 때문에 None이라고 지정해 줌 \n",
    "y = tf.placeholder(tf.float32, shape=[None,1])   \n",
    "\n",
    "beta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"beta\")\n",
    "y_pred = tf.sigmoid(tf.matmul(X, beta, name=\"predictions\"))\n",
    "cost = -tf.reduce_mean(y*tf.log(y_pred) + (1-y)*tf.log(1-y_pred)) # binary cross entropy \n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 20  # beta1 에서 beta2 로 갈 때 20개의 데이터만 쓴다 \n",
    "n_batches = m//batch_size  # 한 바퀴 다 돌아간다 \n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SpZVEKy5nYQZ"
   },
   "outputs": [],
   "source": [
    "XX = scaled_mydata_exp_plus_bias # X data\n",
    "YY = mydata_rep.reshape(-1, 1)   # y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "IAovdrzinQvj",
    "outputId": "23fc4a2a-e942-4cf9-a369-eb41a83f12c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Cost = 0.7846402\n",
      "Epoch 1000 Cost = 0.5897516\n",
      "Epoch 2000 Cost = 0.5844848\n",
      "Epoch 3000 Cost = 0.5820527\n",
      "Epoch 4000 Cost = 0.58042926\n",
      "Epoch 5000 Cost = 0.579215\n",
      "Epoch 6000 Cost = 0.57827306\n",
      "Epoch 7000 Cost = 0.57753\n",
      "Epoch 8000 Cost = 0.57693726\n",
      "Epoch 9000 Cost = 0.5764604\n",
      "Epoch 10000 Cost = 0.57607436\n",
      "Epoch 11000 Cost = 0.5757603\n",
      "Epoch 12000 Cost = 0.5755037\n",
      "Epoch 13000 Cost = 0.5752934\n",
      "Epoch 14000 Cost = 0.57512087\n",
      "Epoch 15000 Cost = 0.57497895\n",
      "Epoch 16000 Cost = 0.57486194\n",
      "Epoch 17000 Cost = 0.5747654\n",
      "Epoch 18000 Cost = 0.57468575\n",
      "Epoch 19000 Cost = 0.57461977\n",
      "Epoch 20000 Cost = 0.57456535\n",
      "Epoch 21000 Cost = 0.5745203\n",
      "Epoch 22000 Cost = 0.574483\n",
      "Epoch 23000 Cost = 0.57445204\n",
      "Epoch 24000 Cost = 0.5744265\n",
      "Epoch 25000 Cost = 0.57440525\n",
      "Epoch 26000 Cost = 0.5743877\n",
      "Epoch 27000 Cost = 0.5743731\n",
      "Epoch 28000 Cost = 0.5743611\n",
      "Epoch 29000 Cost = 0.5743511\n",
      "[[-3.263607 ]\n",
      " [ 1.8564334]\n",
      " [ 2.8801005]\n",
      " [-2.2476957]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(30000): # 데이터 30000번 사용, 20개씩 사용해서 beta 0 에서 beta 1000, 이걸 처음부터 가는걸 30000번 \n",
    "        \n",
    "        for i in range(n_batches): # 여기서 1000바퀴 \n",
    "            start = i * batch_size # 0, 20, ...\n",
    "            end = start+batch_size # 20, 40, ... \n",
    "            \n",
    "            sess.run(training_op, feed_dict={X:XX[start:end,:], # optimization에 쓰일 x에 20개씩, y에 20개씩 넣어준다 \n",
    "                                             y:YY[start:end,:]\n",
    "                                            }) # placeholder에 사전형식으로 넣어줌 \n",
    "\n",
    "            best_beta2 = beta.eval() # beta update \n",
    "\n",
    "        ttt = sess.run(cost, feed_dict={X:XX, y: YY}) # 한 바퀴 돌 때 마다 cost 얼만큼 되는지 ... \n",
    "        \n",
    "        if epoch % 1000 == 0 :\n",
    "            print(\"Epoch\", epoch, \"Cost =\", ttt) # 출력 \n",
    "\n",
    "print(best_beta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "CHvFk6yRrFBo",
    "outputId": "a6ca78c5-1d97-47c4-fc08-d5facc909e85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -3.26360703],\n",
       "       [1485.14671326],\n",
       "       [  11.52040195],\n",
       "       [  -8.99078274]])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비교해 보아야 할 beta 값 \n",
    "c2_beta_value = np.multiply(best_beta2, mydata_exp_plus_bias.max(axis=0).reshape(-1,1))\n",
    "c2_beta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LG2ok8sTQ06c"
   },
   "source": [
    "## (d) beta0, beta1, beta2, beta3 값들을 위의 3가지 방법에 대해서 구하고 비교하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R: [[-3.449548, 0.002294, 0.777014, -0.560031]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "vyTnmJ11Q9Zj",
    "outputId": "57e01067-9a15-4f3f-d640-2f2b3c903bdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.82422534e-01],\n",
       "       [ 2.83148956e+02],\n",
       "       [ 2.41671610e+00],\n",
       "       [-1.75203180e+00]])"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_beta_value # X'X를 통해 beta 값 구했을 때 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "mWt8c6B1sVaX",
    "outputId": "53dd1c64-38cb-4a3f-90e0-92aacc150b45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.61797166e-01],\n",
       "       [ 1.10302849e+03],\n",
       "       [ 1.37124813e+00],\n",
       "       [-9.39203358e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_beta_value # gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "OQ0SfSoSsYOw",
    "outputId": "7ae087a1-52d3-4539-f2fc-5c09b54976d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -3.26360703],\n",
       "       [1485.14671326],\n",
       "       [  11.52040195],\n",
       "       [  -8.99078274]])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2_beta_value # gradient descent + mini batch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EbLjiEGqQ5N2"
   },
   "source": [
    "## (e) log-likelihood function 을 구하고 위의 3가지 방법에 대해서 구하고 비교하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AikUigDLUPhL"
   },
   "source": [
    "#### cost = -mean(y x tf.log(y_pred) + (1-y) x tf.log(1-y_pred))\n",
    ">* R : 0.5743022\n",
    "* only Gradient Descent : 0.5797468\n",
    "* GD + Mini Batch : 0.57432866\n",
    "\n",
    "\n",
    "* beta 값은 다 다르게 나오지만, 3가지 방법 모두 cost function의 최종값은 0.57 정도에서 끝난다! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KGqd6DGhXSZ0"
   },
   "source": [
    "# PART 2. 긍정/부정리뷰 예측 모델 설계 (IMDB data) \n",
    "\n",
    "#### Neural Network 구조 \n",
    ">* 0층의 입력데이터는 x_train\n",
    "* 1층은 hidden unit 의 갯수가 16, activation function = \"relu\"\n",
    "* 2층은 hidden unit 의 갯수가 16, activation function = \"relu\"\n",
    "* 3층은 출력층으로 p_hat 하나를 출력하고, , activation function = \"sigmoid\"\n",
    "\n",
    ">* model fitting시 batch size = 512로 하고, 각 데이터가 평균 4번씩 (epoch=4) 사용 될수 있도록 하세요. 필요시 epoch size를 늘릴 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1jV_1kWX5_c"
   },
   "source": [
    "## (a) Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "LxD562oSpz8s",
    "outputId": "2fe2e82c-f9f9-4d0f-d526-a2a74c78e697"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) # 자주 나타난 10000개의 word만 keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "p6sWi7gDqK1j",
    "outputId": "664fdd3f-ca01-417d-8d0d-c0f113ef2980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] 1\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMHquFBqrQzp"
   },
   "outputs": [],
   "source": [
    "# Encoding the integer sequences into a binary matrix\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension)) # (len(sequence), dimension) shape의 zero vector 만들기 \n",
    "\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1. # 해당 순서의 단어가 존재하면, 1로 바꿔줌 \n",
    "\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HkXvAspAug4m"
   },
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sYePQbx2uYI_",
    "outputId": "065f0223-9b4e-47c8-d579-424963e29b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 0. 0. 0.] 1.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-SaZUcY1yGTp",
    "outputId": "56a5ba55-00e2-4dad-974e-74f8a58cbc29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000) (25000, 10000) (25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cafZYV5uX_I_"
   },
   "source": [
    "## (b) 모델에서 사용된 parameter의 차원 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dim](https://user-images.githubusercontent.com/43749571/95837081-25212600-0d7b-11eb-95a1-992b8998dd46.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwC27OlcYEVh"
   },
   "source": [
    "## (c) Modeling \n",
    "* 신경망 모델을 tensorflow를 사용하여 모델링하고, binary_cross entropy 손실함수 (logistic regression에서 log-likelihood function에 minus sign을 붙인 것) 이를 적절한 옵티마이져를 사용하여 model fitting을 실시하세요. 이 과정에 대한 간략한 코멘트를 추가해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cu88NeadQi69"
   },
   "outputs": [],
   "source": [
    "y_train_onehot = tf.one_hot(y_train, 2)\n",
    "y_train_onehot = tf.reshape(y_train_onehot, [-1, 2]) # placeholder에 맞게끔 shape 조정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9aZHwOTEREDq"
   },
   "outputs": [],
   "source": [
    "y_test_onehot = tf.one_hot(y_test, 2)\n",
    "y_test_onehot = tf.reshape(y_test_onehot, [-1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JhmnijqARX7V"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_train_onehot = y_train_onehot.eval()\n",
    "    y_test_onehot = y_test_onehot.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "QF6pD_JpVFFT",
    "outputId": "3c5c2c99-ea1a-41e5-90bf-8edf0a2bd6bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "fYnTRbIbVGWe",
    "outputId": "1bb4cc91-1414-4988-d958-ed09440c6255"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KBC9KuXicnMQ",
    "outputId": "688b7efc-04fe-4db8-dd8b-e92094b3f820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2) (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_onehot.shape, y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUr4VpcC340j"
   },
   "outputs": [],
   "source": [
    "# define the constant \n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 150  # 100 repetition for the whole data\n",
    "batch_size = 512 # num of batch per one gradient descent\n",
    "input_size = 10000\n",
    "hidden1_size = 16\n",
    "hidden2_size = 16 \n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32llj6kF4QoJ"
   },
   "outputs": [],
   "source": [
    "# define placeholder \n",
    "\n",
    "X=tf.placeholder(tf.float32, shape=[None, 10000])\n",
    "y=tf.placeholder(tf.float32, shape=[None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFP_FOEL4QgL"
   },
   "outputs": [],
   "source": [
    "# Neural Net \n",
    "W1 = tf.Variable(tf.random_normal(shape=[input_size, hidden1_size]))\n",
    "b1 = tf.Variable(tf.random_normal(shape=[hidden1_size]) )\n",
    "a1 = tf.nn.relu(tf.matmul(X, W1)+b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal(shape=[hidden1_size, hidden2_size]))\n",
    "b2 = tf.Variable(tf.random_normal(shape=[hidden2_size]) )\n",
    "a2 = tf.nn.relu(tf.matmul(a1, W2)+b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal(shape=[hidden2_size, output_size]))\n",
    "b3 = tf.Variable(tf.random_normal(shape=[output_size]) )\n",
    "z3 = tf.matmul(a2, W3)+b3\n",
    "\n",
    "\n",
    "# return z3\n",
    "logits = z3\n",
    "y_pred = tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "# loss \n",
    "# loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_pred), axis=1))\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits = y_pred, labels = y)\n",
    "\n",
    "\n",
    "# training \n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "# batch \n",
    "n_batches = x_train.shape[0]//batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BrPtnPbCGgp"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPmTSuxpYYiw"
   },
   "source": [
    "## (d) train data의 정확도 / (e) test data의 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "h94e3OBkCcp8",
    "outputId": "5a72ca94-122d-43d5-8d36-2a6808ebf9fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, accuracy : 0.505079984664917\n",
      "epoch : 10, accuracy : 0.5879600048065186\n",
      "epoch : 20, accuracy : 0.6444000005722046\n",
      "epoch : 30, accuracy : 0.669439971446991\n",
      "epoch : 40, accuracy : 0.7075600028038025\n",
      "epoch : 50, accuracy : 0.7265999913215637\n",
      "epoch : 60, accuracy : 0.7442799806594849\n",
      "epoch : 70, accuracy : 0.7524799704551697\n",
      "epoch : 80, accuracy : 0.7640399932861328\n",
      "epoch : 90, accuracy : 0.7768399715423584\n",
      "epoch : 100, accuracy : 0.7853999733924866\n",
      "epoch : 110, accuracy : 0.7945600152015686\n",
      "epoch : 120, accuracy : 0.8060799837112427\n",
      "epoch : 130, accuracy : 0.8157600164413452\n",
      "epoch : 140, accuracy : 0.821399986743927\n",
      "epoch : 150, accuracy : 0.8271200060844421\n",
      "===========================================\n",
      "Train accuracy : 0.8271200060844421\n",
      "Test accuracy : 0.743120014667511\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(num_epochs+1):  # 100+1 epoch \n",
    "        \n",
    "        for i in range(n_batches):  \n",
    "            start = i * batch_size \n",
    "            end = start+batch_size \n",
    "            \n",
    "            sess.run(train_step, feed_dict={X:x_train[start:end,:], y:y_train_onehot[start:end,:]}) \n",
    "\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1)) # 확률값 높은 곳으로 예측 \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))            \n",
    "\n",
    "        if epoch % 10 == 0 : \n",
    "            print(\"epoch : {}, accuracy : {}\".format(epoch, sess.run(accuracy, feed_dict={X:x_train, y:y_train_onehot})))\n",
    "\n",
    "\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1)) # 확률값 높은 곳으로 예측 \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))  \n",
    "\n",
    "    print(\"===========================================\")\n",
    "    print(\"Train accuracy : {}\".format(sess.run(accuracy, feed_dict={X:x_train, y:y_train_onehot})))\n",
    "    print(\"Test accuracy : {}\".format(sess.run(accuracy, feed_dict={X:x_test, y:y_test_onehot})))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_202STG18.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
