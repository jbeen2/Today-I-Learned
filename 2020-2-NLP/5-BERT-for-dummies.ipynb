{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5-BERT-for-dummies.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1Gh_V50zfmicEcKRmj8DFfMPA6jmJR-Vu",
      "authorship_tag": "ABX9TyNAQJDIxh14hFyClz9ATRPI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbeen2/Today-I-Learned/blob/main/2020-2-NLP/5-BERT-for-dummies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvwfqE_UN1CF"
      },
      "source": [
        "# BERT\n",
        "![Transformer](https://blog.kakaocdn.net/dn/Cz2K8/btqCwX7yfGQ/txkY1MEKNklEiDN0x4K9b0/img.png)\n",
        "* Bidirectional Encoder Representations from Transformers \n",
        "* **Attention mechanism**을 사용하는, **Transformer** Encoder-Decoder 기반 모델입니다. \n",
        "* BERT는 Transformer 구조에서 **왼쪽, Encoder** 부분만 사용합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZUPBWnc4aRF"
      },
      "source": [
        "## Positional Encoding \n",
        "* Transformer 는 Convolution, Recurrent를 사용하지 않는, **Attention mechanism** 만 사용하여 속도를 향상시킨 모델입니다. \n",
        "* 위치 정보가 들어가는 RNN과 달리, Transformer는 **위치 정보**를 추가해 주어야 합니다. \n",
        "* 이를 위해 **sin**, **cos** 함수를 사용합니다. \n",
        "    - 전체 차원의 수가 짝수일 때는 sin 함수, 홀수일 때는 cos 함수의 값을 따릅니다. \n",
        "    - 위치 정보를 정수로 표현하면 모델에 끼치는 영향력이 지나치게 커질 수 있는데, sin, cos 함수를 사용하면 (-1, 1) 값으로 표현되기 때문에 이러한 점을 보완할 수 있습니다. \n",
        "\n",
        "```python\n",
        "# input embedding \n",
        "e = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsCJmgwM5ZX0"
      },
      "source": [
        "## Multi-Head Attention \n",
        "* Encoder Block 의 가장 핵심적인 부분입니다. \n",
        "* Attention  \n",
        "    - Q(현재 단어)와 가장 비슷한 K를 찾은 후, K에 해당하는 V를 찾는 과정입니다. \n",
        "        - Q : Query, 찾고자 하는 대상 \n",
        "        - K : Key, 저장된 데이터를 찾고자 할 때 참조하는 대상 \n",
        "        - V : Value, 저장되는 데이터\n",
        "    - K를 통해서는 각 단어와 연관성의 확률을 계산하고, \n",
        "    - V는 그 확률을 사용해 attention 값을 계산합니다.     \n",
        "    - .\n",
        "    - Recurrent 구조에서는 시간이 흐를수록, 앞의 몇 가지 유용한 정보들을 손실하게 됩니다. \n",
        "    - 계산한 값에서 **높은 확률 값을 갖는 정보를 다시 한 번 참고**해서,\n",
        "    - 손실했던 정보를 반영하는 것이 Attention mechanism 입니다. \n",
        "* **Multi-head Attention** \n",
        "    - 서로 다른 가중치 행렬을 이용해 Attention 을 h번 계산한 다음 이를 Concatenate 합니다. \n",
        "    - MultiHead(Q,K,V) = [head1 ; ...; headh] * WO\n",
        "    - . \n",
        "    1. Bert-Base 모델은 12개의 Encoder Block을 사용합니다. \n",
        "    2. 각각의 token 벡터 768 차원을 헤드 수 만큼인 12개 등분하여, \n",
        "    3. 64개씩 12조각으로 차례대로 분리합니다. \n",
        "    4. 따라서 768차원의 벡터는 각각 부위별로 12번 Attention 을 받은 결과가 됩니다.\n",
        "    5. Attention 결과를 Point-Wise Feed Forward Network를 통과시켜, output을 도출하게 됩니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPUIFoIoObiJ"
      },
      "source": [
        "# Code \n",
        "* https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03 \n",
        "* [ATIS dataset](https://www.kaggle.com/siddhadev/atis-dataset-from-ms-cntk?fbclid=IwAR2HTefgyVO4Kz0VhjFA0gH1ACc72CrA_k18RcDfgG5kQacHv_ZLMhEGj_Y&select=atis.test.pkl)(Airline Tranvel Information System dataset)을 이용하여 query label **Classification** 하기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTmqEUH6NpG7",
        "outputId": "1dbb5eb4-88b3-4791-a023-34801714eba7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bNF-XGVPXSa"
      },
      "source": [
        "# !pip install urllib3==1.25.10\n",
        "# !pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo7cLExzPktr"
      },
      "source": [
        "% matplotlib inline \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import io\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rohzq45fPWs8"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RyDVsupAPw3s",
        "outputId": "b457fc28-439e-45ec-b352-ec11881646bd"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVrGargXP7Pc"
      },
      "source": [
        "## Data Preprocess "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GQYZ_HXpggm"
      },
      "source": [
        "### 1. Data Load "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9iipdhLPz-8",
        "outputId": "b4c905c2-9ec9-46be-e6e5-1cee0c439736"
      },
      "source": [
        "cd /content/drive/MyDrive/Stat/2020-2-NLP/5-BERT "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Stat/2020-2-NLP/5-BERT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDgQuuCYQAo8"
      },
      "source": [
        "def load_ds(fname='atis.train.pkl', verbose=True):\n",
        "    with open(fname, 'rb') as stream:\n",
        "        ds, dicts = pickle.load(stream)\n",
        "\n",
        "    print('Done  loading: ', fname)\n",
        "    print('      samples: {:4d}'.format(len(ds['query'])))\n",
        "    print('   vocab_size: {:4d}'.format(len(dicts['token_ids'])))\n",
        "    print('   slot count: {:4d}'.format(len(dicts['slot_ids'])))\n",
        "    print(' intent count: {:4d}'.format(len(dicts['intent_ids'])))\n",
        "\n",
        "    return ds, dicts"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx7xawaOWaif"
      },
      "source": [
        "# convert Pickle file to arrays\n",
        "def load_atis(filename, add_start_end_token=False, verbose=True):\n",
        "    train_ds, dicts = load_ds(os.path.join(filename), verbose)\n",
        "    t2i, s2i, in2i = map(dicts.get, ['token_ids', 'slot_ids','intent_ids'])\n",
        "    i2t, i2s, i2in = map(lambda d: {d[k]:k for k in d.keys()}, [t2i,s2i,in2i])\n",
        "    query, slots, intent =  map(train_ds.get, ['query', 'slot_labels', 'intent_labels'])\n",
        "\n",
        "    if add_start_end_token:\n",
        "        i2s[178] = 'BOS'    # start token index 부여 \n",
        "        i2s[179] = 'EOS'    # end token index 부여 \n",
        "        s2i['BOS'] = 178\n",
        "        s2i['EOS'] = 179\n",
        "\n",
        "    input_tensor = []\n",
        "    target_tensor = []\n",
        "    query_data = []\n",
        "    intent_data = []\n",
        "    slot_data = []\n",
        "    to_show = np.random.randint(0, len(query)-1, 5)\n",
        "    \n",
        "    for i in range(len(query)):\n",
        "        input_tensor.append(query[i])\n",
        "        slot_text = []\n",
        "        slot_vector = []\n",
        "        for j in range(len(query[i])):\n",
        "            slot_text.append(i2s[slots[i][j]])\n",
        "            slot_vector.append(slots[i][j])\n",
        "        if add_start_end_token:\n",
        "            slot_text[0] = 'BOS'    # 문장 시작에 BOS \n",
        "            slot_vector[0] = 178\n",
        "            slot_text[-1] = 'EOS'   # 문장 끝에 EOS \n",
        "            slot_vector[-1]= 179\n",
        "        target_tensor.append(slot_vector)\n",
        "        q = ' '.join(map(i2t.get, query[i]))\n",
        "        query_data.append(q.replace('BOS', '').replace('EOS',''))\n",
        "        intent_data.append(i2in[intent[i][0]])\n",
        "        slot = ' '.join(slot_text)\n",
        "        slot_data.append(slot[1:-1])\n",
        "        if i in to_show and verbose:\n",
        "            print('Query text:', q)\n",
        "            print('Query vector: ', query[i])\n",
        "            print('Intent label: ', i2in[intent[i][0]])\n",
        "            print('Slot text: ', slot)\n",
        "            print('Slot vector: ', slot_vector)\n",
        "            print('*'*74)\n",
        "            \n",
        "    query_data = np.array(query_data)\n",
        "    intent_data = np.array(intent_data)\n",
        "    slot_data = np.array(slot_data)\n",
        "    intent_data_label = np.array(intent).flatten()\n",
        "    \n",
        "    return t2i, s2i, in2i, i2t, i2s, i2in, input_tensor, target_tensor, query_data, intent_data, intent_data_label, slot_data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejrw4qgyW7W2",
        "outputId": "ded9c948-3a26-4def-9264-9c526d565006"
      },
      "source": [
        "# load ATIS training dataset  \n",
        "t2i_train, s2i_train, in2i_train, i2t_train, i2s_train, i2in_train, \\\n",
        "input_tensor_train, target_tensor_train, \\\n",
        "query_data_train, intent_data_train, intent_data_label_train, slot_data_train = load_atis('atis.train.pkl')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done  loading:  atis.train.pkl\n",
            "      samples: 4978\n",
            "   vocab_size:  943\n",
            "   slot count:  129\n",
            " intent count:   26\n",
            "Query text: BOS what does it cost to fly from boston to oakland on united airlines EOS\n",
            "Query vector:  [178 916 376 499 327 851 431 444 266 851 644 654 887 200 179]\n",
            "Intent label:  airfare\n",
            "Slot text:  O O O O O O O O B-fromloc.city_name O B-toloc.city_name O B-airline_name I-airline_name O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 128, 128, 128, 48, 128, 78, 128, 2, 83, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS which airline offers the cheapest rate going from dallas to baltimore on july fourth EOS\n",
            "Query vector:  [178 920 199 650 827 296 709 452 444 339 851 247 654 507 439 179]\n",
            "Intent label:  airline\n",
            "Slot text:  O O O O O B-cost_relative O O O B-fromloc.city_name O B-toloc.city_name O B-depart_date.month_name B-depart_date.day_number O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 21, 128, 128, 128, 48, 128, 78, 128, 28, 27, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS i want to travel from kansas city to st. paul and be there by dinnertime EOS\n",
            "Query vector:  [178 479 902 851 867 444 511 301 851 789 673 215 250 831 277 368 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O O O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name I-toloc.city_name O O O B-depart_time.time_relative B-depart_time.period_of_day O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 128, 48, 110, 128, 78, 125, 128, 128, 128, 36, 33, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS does the philadelphia airport have a name EOS\n",
            "Query vector:  [178 376 827 678 203 463 180 612 179]\n",
            "Intent label:  airport\n",
            "Slot text:  O O O B-airport_name I-airport_name O O O O\n",
            "Slot vector:  [128, 128, 128, 4, 84, 128, 128, 128, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS i 'd like a cheap flight from dallas to baltimore on january first EOS\n",
            "Query vector:  [178 479   0 545 180 295 428 444 339 851 247 654 502 425 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O O O O B-flight_mod O O B-fromloc.city_name O B-toloc.city_name O B-depart_date.month_name B-depart_date.day_number O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 42, 128, 128, 48, 128, 78, 128, 28, 27, 128]\n",
            "**************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OyEKfN2W-v2",
        "outputId": "2eadf055-d66d-45b9-b411-c232c5c19f9c"
      },
      "source": [
        "# load ATIS test dataset\n",
        "t2i_test, s2i_test, in2i_test, i2t_test, i2s_test, i2in_test, \\\n",
        "input_tensor_test, target_tensor_test, \\\n",
        "query_data_test, intent_data_test, intent_data_label_test, slot_data_test = load_atis('atis.test.pkl')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done  loading:  atis.test.pkl\n",
            "      samples:  893\n",
            "   vocab_size:  943\n",
            "   slot count:  129\n",
            " intent count:   26\n",
            "Query text: BOS which flights leave april twelfth from indianapolis and arrive in montreal around 10 pm EOS\n",
            "Query vector:  [178 920 429 537 227 878 444 489 215 236 482 604 231  10 689 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O O O B-depart_date.month_name B-depart_date.day_number O B-fromloc.city_name O O O B-toloc.city_name B-arrive_time.time_relative B-arrive_time.time I-arrive_time.time O\n",
            "Slot vector:  [128, 128, 128, 128, 28, 27, 128, 48, 128, 128, 128, 78, 15, 14, 89, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS list the distance in miles from san francisco international airport to san francisco downtown EOS\n",
            "Query vector:  [178 549 827 373 482 594 444 739 440 496 203 851 739 440 380 179]\n",
            "Intent label:  distance\n",
            "Slot text:  O O O O O O O B-fromloc.airport_name I-fromloc.airport_name I-fromloc.airport_name I-fromloc.airport_name O B-toloc.city_name I-toloc.city_name O O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 128, 128, 47, 109, 109, 109, 128, 78, 125, 128, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS show me the cheapest one way fare from san francisco to houston on february twenty eighth 1994 EOS\n",
            "Query vector:  [178 770 581 827 296 656 906 414 444 739 440 851 476 654 416 881 394  64\n",
            " 179]\n",
            "Intent label:  airfare\n",
            "Slot text:  O O O O B-cost_relative B-round_trip I-round_trip O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name O B-depart_date.month_name B-depart_date.day_number I-depart_date.day_number B-depart_date.year O\n",
            "Slot vector:  [128, 128, 128, 128, 21, 66, 119, 128, 128, 48, 110, 128, 78, 128, 28, 27, 95, 30, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS list flights from milwaukee to san jose on wednesday EOS\n",
            "Query vector:  [178 549 429 444 595 851 739 506 654 908 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-depart_date.day_name O\n",
            "Slot vector:  [128, 128, 128, 128, 48, 128, 78, 125, 128, 26, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS list delta flights from seattle to salt lake city with aircraft type EOS\n",
            "Query vector:  [178 549 350 429 444 752 851 736 521 301 925 196 883 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O B-airline_name O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name I-toloc.city_name O O O O\n",
            "Slot vector:  [128, 128, 2, 128, 128, 48, 128, 78, 125, 125, 128, 128, 128, 128]\n",
            "**************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "NW7-JUoaYfOz",
        "outputId": "b90d1c03-e137-4d54-c5cc-71915e604cee"
      },
      "source": [
        "# [최종 예측해야 할 값] 질문(query)에 대한 intent \n",
        "\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "df = pd.DataFrame({'intent': intent_data_train, 'query': query_data_train})\n",
        "\n",
        "df_small = pd.DataFrame(columns=['intent', 'query'])\n",
        "j = 0\n",
        "for i in df.intent.unique():\n",
        "    df_small.loc[j] = df[df.intent==i].iloc[0]\n",
        "    j = j+1\n",
        "    \n",
        "df_small"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intent</th>\n",
              "      <th>query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>flight</td>\n",
              "      <td>i want to fly from boston at 838 am and arrive in denver at 1110 in the morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>flight_time</td>\n",
              "      <td>what is the arrival time in san francisco for the 755 am flight leaving washington</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>airfare</td>\n",
              "      <td>cheapest airfare from tacoma to orlando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aircraft</td>\n",
              "      <td>what kind of aircraft is used on a flight from cleveland to dallas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ground_service</td>\n",
              "      <td>what kind of ground transportation is available in denver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>airport</td>\n",
              "      <td>what 's the airport at orlando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>airline</td>\n",
              "      <td>which airline serves denver pittsburgh and atlanta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>distance</td>\n",
              "      <td>how far is it from orlando airport to orlando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>abbreviation</td>\n",
              "      <td>what is fare code h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ground_fare</td>\n",
              "      <td>how much does the limousine service cost within pittsburgh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>quantity</td>\n",
              "      <td>please tell me how many nonstop flights there are from boston to atlanta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>city</td>\n",
              "      <td>what city is the airport mco in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>flight_no</td>\n",
              "      <td>flight numbers from columbus to minneapolis tomorrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>capacity</td>\n",
              "      <td>how many seats in a 100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>flight+airfare</td>\n",
              "      <td>give me the flights and fares on december twenty seventh from indianapolis to orlando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>meal</td>\n",
              "      <td>show me all meals on flights from atlanta to washington</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>restriction</td>\n",
              "      <td>what are the air restrictions on flights from pittsburgh to atlanta for the airfare of 416 dollars</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>airline+flight_no</td>\n",
              "      <td>airline and flight number from columbus to minneapolis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ground_service+ground_fare</td>\n",
              "      <td>what ground transportation is available from the pittsburgh airport to downtown and how much does it cost</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>airfare+flight_time</td>\n",
              "      <td>show me the costs and times for flights from san francisco to atlanta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>cheapest</td>\n",
              "      <td>show me the cheapest fare in the database</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>aircraft+flight+flight_no</td>\n",
              "      <td>i want to fly from detroit to st. petersburg on northwest airlines and leave around 9 am tell me what aircraft are used by this flight and tell me the flight number</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        intent                                                                                                                                                                   query\n",
              "0   flight                       i want to fly from boston at 838 am and arrive in denver at 1110 in the morning                                                                                      \n",
              "1   flight_time                  what is the arrival time in san francisco for the 755 am flight leaving washington                                                                                   \n",
              "2   airfare                      cheapest airfare from tacoma to orlando                                                                                                                              \n",
              "3   aircraft                     what kind of aircraft is used on a flight from cleveland to dallas                                                                                                   \n",
              "4   ground_service               what kind of ground transportation is available in denver                                                                                                            \n",
              "5   airport                      what 's the airport at orlando                                                                                                                                       \n",
              "6   airline                      which airline serves denver pittsburgh and atlanta                                                                                                                   \n",
              "7   distance                     how far is it from orlando airport to orlando                                                                                                                        \n",
              "8   abbreviation                 what is fare code h                                                                                                                                                  \n",
              "9   ground_fare                  how much does the limousine service cost within pittsburgh                                                                                                           \n",
              "10  quantity                     please tell me how many nonstop flights there are from boston to atlanta                                                                                             \n",
              "11  city                         what city is the airport mco in                                                                                                                                      \n",
              "12  flight_no                    flight numbers from columbus to minneapolis tomorrow                                                                                                                 \n",
              "13  capacity                     how many seats in a 100                                                                                                                                              \n",
              "14  flight+airfare               give me the flights and fares on december twenty seventh from indianapolis to orlando                                                                                \n",
              "15  meal                         show me all meals on flights from atlanta to washington                                                                                                              \n",
              "16  restriction                  what are the air restrictions on flights from pittsburgh to atlanta for the airfare of 416 dollars                                                                   \n",
              "17  airline+flight_no            airline and flight number from columbus to minneapolis                                                                                                               \n",
              "18  ground_service+ground_fare   what ground transportation is available from the pittsburgh airport to downtown and how much does it cost                                                            \n",
              "19  airfare+flight_time          show me the costs and times for flights from san francisco to atlanta                                                                                                \n",
              "20  cheapest                     show me the cheapest fare in the database                                                                                                                            \n",
              "21  aircraft+flight+flight_no    i want to fly from detroit to st. petersburg on northwest airlines and leave around 9 am tell me what aircraft are used by this flight and tell me the flight number "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYoVL7uxY-nW"
      },
      "source": [
        "### 2. BERT Sentence  \n",
        "* [CLS] : at the **beginning** of our text\n",
        "* [SEP] : to mark the **end** of a sentence, or the **separation** between two sentences\n",
        "\n",
        "---\n",
        "\n",
        "BERT는 한 문장 or 두 문장만 입력 가능합니다. \n",
        "1. 한 문장 : [CLS] The man went to the store. [SEP] \n",
        "2. 두 문장 : [CLS] The man went to the store. [SEP] He bought a gallon of milk. [SEP]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBE_fIgwXUzJ",
        "outputId": "35d8d669-f800-4c69-c3af-d2569f97218b"
      },
      "source": [
        "# BERT model의 input에 맞게 query 재가공 (special token 추가)\n",
        "sentences = [\"[CLS] \" + query + \" [SEP]\" for query in query_data_train]\n",
        "print(sentences[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS]  i want to fly from boston at 838 am and arrive in denver at 1110 in the morning  [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAtKQqaeas9J"
      },
      "source": [
        "### BERT Tokenizer \n",
        "* BERT Tokenizer 는 **WordPiece Model** 기반으로 tokenizing을 수행합니다. \n",
        "    - WordPiece Model : **Character Embedding + Word Embedding** 두 가지를 혼합한 모델\n",
        "        1. 먼저 캐릭터 단위로 분리를 합니다.\n",
        "        2. 그 다음, 자주 나오는 캐릭터들을 병합하여 하나의 토큰으로 만듭니다. \n",
        "            - 이렇게 하면 의미가 있는 캐릭터들이 묶여지기 때문에 캐릭터 임베딩과 워드 임베딩의 장점이 합쳐집니다.\n",
        "            - 또한 형태소분석이 필요 없기 때문에 다양한 언어에 유연하게 적용할 수도 있습니다. (한국어, 일본어)\n",
        "\n",
        "    - Process\n",
        "        1. original word가 subword로 쪼개집니다. \n",
        "        2. \"##bed\"는 어떤 단어의 일부, subword라는 뜻입니다. 독립적인 단어 \"bed\"랑 다르다는 것을 보여주기 위해 사용됩니다. \n",
        "        3. 전체 단어가 BERT vocab에 없으면 **subword로 분해하는 과정**을 거칩니다.\n",
        "        4. vocab에서 찾을 때까지 분해하고, 끝까지 못 찾으면 철자 하나씩까지 분해하게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPJAiU06Zo_D",
        "outputId": "4630a865-0665-464c-c5bf-76092ae33802"
      },
      "source": [
        "# BERT tokenizer를 불러와서, BERT vocabulary 의 형태에 맞게 tokenize 합니다. \n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print(\"* Tokenize the first sentence *\")\n",
        "print(tokenized_texts[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 5888079.28B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "* Tokenize the first sentence *\n",
            "['[CLS]', 'i', 'want', 'to', 'fly', 'from', 'boston', 'at', '83', '##8', 'am', 'and', 'arrive', 'in', 'denver', 'at', '111', '##0', 'in', 'the', 'morning', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUyv-YmycHCe"
      },
      "source": [
        "### 3. BERT input \n",
        "* BERT model에 적용하기 위해서는, input 형식에 맞게 데이터를 만드는 과정이 필요합니다. \n",
        "* BERT pre-training 단계에서는 두 가지 task를 수행합니다. \n",
        "    1. Next Sentence Prediction \n",
        "    2. Masked Language Model \n",
        "* 따라서 위의 과정에 맞는 데이터를 만들어서 적용시키는 과정이 필요합니다. \n",
        "![대체 텍스트](https://mino-park7.github.io/images/2019/02/bert-input-representation.png)\n",
        "\n",
        "--- \n",
        "\n",
        "* **input ids** : 각 token마다 index를 부여해서, vector로 만들어 줍니다. \n",
        "* **segment mask** \n",
        "    - **Next Sentence Prediction** \n",
        "        - 두 개의 문장을 주고, 두 번째 문장이 코퍼스 내에서 첫 번째 문장의 **바로 다음에 오는지** 여부를 예측하도록 하는 방식입니다. \n",
        "    - input 문장이 하나면 segment ID 모두 1으로 부여합니다. (input 문장 + 마지막 [SEP] 까지 1)\n",
        "    - input 문장이 두개면 첫 문장은 0, 다음 문장은 1로 줘서 구분합니다.\n",
        "* **attention mask** \n",
        "    - **Masked Language Model**\n",
        "        - 문장의 다음 단어를 예측하는 것이 아니라, 문장 내 **랜덤한 단어를 마스킹**하고 이를 예측하도록 하는 방식입니다. \n",
        "        - **마스킹 된 토큰을 맞추도록 학습한 결과**를 직접 벡터로 갖는 방식입니다. \n",
        "        - 마스킹은 전체 단어의 15% 정도만 진행하며, \n",
        "        - 모든 토큰을 마스킹하는 것이 아니라 80% 정도만 [Mask] 처리하고, 10%는 랜덤한 단어, 나머지 10%는 정상적인 단어로 유지합니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DAMfd8Zaghv"
      },
      "source": [
        "# 최대 길이 지정 \n",
        "MAX_LEN = 128\n",
        "\n",
        "\n",
        "# tokenizing & padding \n",
        "# tokenizing : token을 숫자 인덱스에 맞추어 변환합니다. \n",
        "# padding : 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채워줍니다. \n",
        "\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfnyra4g6F8-",
        "outputId": "ed653008-65fe-4deb-f145-09325cc40402"
      },
      "source": [
        "print('* sentence : ',  sentences[0])\n",
        "print('* tokenized sentence : ',  tokenized_texts[0])\n",
        "print(\"=====\" * 30)\n",
        "print('* token id : ',  input_ids[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* sentence :  [CLS]  i want to fly from boston at 838 am and arrive in denver at 1110 in the morning  [SEP]\n",
            "* tokenized sentence :  ['[CLS]', 'i', 'want', 'to', 'fly', 'from', 'boston', 'at', '83', '##8', 'am', 'and', 'arrive', 'in', 'denver', 'at', '111', '##0', 'in', 'the', 'morning', '[SEP]']\n",
            "======================================================================================================================================================\n",
            "* token id :  [  101  1045  2215  2000  4875  2013  3731  2012  6640  2620  2572  1998\n",
            "  7180  1999  7573  2012 11118  2692  1999  1996  2851   102     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF_WRwoL4yAg",
        "outputId": "43883127-c051-45aa-d687-385132ab3272"
      },
      "source": [
        "# train set의 4978 query에 대해 tokenizing  \n",
        "# query의 첫 단어는 [CLS] = 101\n",
        "\n",
        "print(input_ids.shape)\n",
        "input_ids"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4978, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 101, 1045, 2215, ...,    0,    0,    0],\n",
              "       [ 101, 2054, 7599, ...,    0,    0,    0],\n",
              "       [ 101, 2054, 2003, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 101, 2029, 7608, ...,    0,    0,    0],\n",
              "       [ 101, 2515, 6803, ...,    0,    0,    0],\n",
              "       [ 101, 2003, 2045, ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y8thnVp6lsc"
      },
      "source": [
        "# initialize attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 padding이 아니면 1, padding이면 0으로 설정합니다. \n",
        "# padding 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도가 향상됩니다. \n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgzjt_FW7K3z",
        "outputId": "9889621b-f15f-49ab-fab9-52255566f2a6"
      },
      "source": [
        "print(\"* attention mask : \", attention_masks[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* attention mask :  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMyGNDu37qMG"
      },
      "source": [
        "### 4. to tensor \n",
        "* BERT model 사용을 위해 (pytorch 사용을 위해) tensor에 올려줍니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdDSPzbD7bZw"
      },
      "source": [
        "# train, validation split \n",
        "labels = intent_data_label_train    # query의 intent (22개)\n",
        "\n",
        "\n",
        "# token id \n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                                   random_state=2020, test_size=0.1)\n",
        "\n",
        "# attention mask \n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                                       random_state=2020, test_size=0.1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XqZ8DvU8dz0"
      },
      "source": [
        "# data를 tensor에 올려줍니다 \n",
        "train_inputs, train_labels = torch.tensor(train_inputs) , torch.tensor(train_labels)\n",
        "validation_inputs, validation_labels = torch.tensor(validation_inputs) , torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5TyA2b1AZ5V",
        "outputId": "f3caf562-2ae8-4bee-c021-2301f7574537"
      },
      "source": [
        "print(\"*** BERT input ***\")\n",
        "print(\"=====\" * 20)\n",
        "print(\"* train input\")\n",
        "print(train_inputs[0])\n",
        "print()\n",
        "print(\"* train label\")\n",
        "print(train_labels[0])\n",
        "print()\n",
        "print(\"* train attention mask\")\n",
        "print(train_masks[0])\n",
        "print()\n",
        "print()\n",
        "print(\"* validation input\")\n",
        "print(validation_inputs[0])\n",
        "print()\n",
        "print(\"* validation label\")\n",
        "print(validation_labels[0])\n",
        "print()\n",
        "print(\"* validation attention mask\")\n",
        "print(validation_masks[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** BERT input ***\n",
            "====================================================================================================\n",
            "* train input\n",
            "tensor([ 101, 2054, 2785, 1997, 2598, 5193, 2003, 2045, 1999, 4407,  102,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "\n",
            "* train label\n",
            "tensor(21)\n",
            "\n",
            "* train attention mask\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "\n",
            "\n",
            "* validation input\n",
            "tensor([ 101, 2265, 1996, 7599, 2008, 2681, 4407, 2008, 2175, 2000, 5865, 2008,\n",
            "        2681, 2220, 2006, 9432, 2851,  102,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "\n",
            "* validation label\n",
            "tensor(14)\n",
            "\n",
            "* validation attention mask\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsFLVTGw8676"
      },
      "source": [
        "# training 을 위한 batch size를 설정해 줍니다. (16 혹은 32 권장)\n",
        "batch_size = 32\n",
        "\n",
        "# DataLoader : data 전체를 사용하지 않고, minibatch 단위로 처리하여 학습의 효율성을 향상시킵니다. \n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)     # [input, mask, label]\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsSRG7FaBYbm"
      },
      "source": [
        "## Modeling "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RkNnAtiHWUf"
      },
      "source": [
        "### 1. Model Load "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv5D69Pn9kiJ",
        "outputId": "18727078-a147-470a-9926-57baf9194793"
      },
      "source": [
        "# 분류를 위한 BERT 모델을 생성합니다. \n",
        "# pre-trained 된 BERT 모델을 불러옵니다. \n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=26)\n",
        "model.cuda()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANNSS_FqHLUd"
      },
      "source": [
        "# optimizer parameter 설정 \n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9O6X8u9HMO6",
        "outputId": "48a4cb9e-a148-4491-d984-5d6e0b781c26"
      },
      "source": [
        "# optimizer \n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12AMetjuB1Dg"
      },
      "source": [
        "# epoch\n",
        "epochs = 4\n",
        "\n",
        "# 총 훈련 step : batch 반복 횟수 * epoch\n",
        "total_steps = len(train_dataloader) * epochs"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHc1lJyUHZl3"
      },
      "source": [
        "### 2. Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohQHPEhgFLIP"
      },
      "source": [
        "# 정확도 계산 함수 (prediction vs labels)\n",
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHyHpQODHiNv"
      },
      "source": [
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))     # hh:mm:ss "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfZUDp8XHsv6",
        "outputId": "f77d5ea1-7904-4aa4-8347-7bf57c42d177"
      },
      "source": [
        "# loss 저장 \n",
        "train_loss_set = []\n",
        "\n",
        "# gradient 초기화 \n",
        "model.zero_grad()\n",
        "\n",
        "# epoch 만큼 반복 \n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # loss 초기화\n",
        "    total_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        " \n",
        " \n",
        "    # training \n",
        "    model.train()\n",
        "        \n",
        "    # DataLoader 에서 batch 만큼 반복하여 가져옵니다. \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # batch를 GPU에 올립니다. \n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # batch에서 데이터를 추출합니다. \n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # 모델 학습 전, optimizer의 gradient를 초기화합니다. \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward             \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # loss를 저장합니다. \n",
        "        train_loss_set.append(outputs.item()) \n",
        "\n",
        "        # Backward : gradient 계산\n",
        "        outputs.backward()\n",
        "\n",
        "        # gradient를 통해 가중치 파라미터를 업데이트 합니다. \n",
        "        optimizer.step()\n",
        "\n",
        "        # 총 loss를 구합니다. \n",
        "        total_loss += outputs.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "\n",
        "    # 평균 loss를 계산합니다. \n",
        "    avg_train_loss = total_loss / nb_tr_steps            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.5f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # evaluation \n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # DataLoader 에서 batch 만큼 반복하여 가져옵니다. \n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # batch를 GPU에 올립니다. \n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # batch에서 데이터를 추출합니다. \n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # evaluation 단계 : gradient 업데이트 하지 않습니다. \n",
        "        with torch.no_grad():     \n",
        "            # Forward \n",
        "            logits = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.5f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    50  of    140.    Elapsed: 0:00:29.\n",
            "  Batch   100  of    140.    Elapsed: 0:00:58.\n",
            "\n",
            "  Average training loss: 0.55902\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98047\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    50  of    140.    Elapsed: 0:00:29.\n",
            "  Batch   100  of    140.    Elapsed: 0:00:58.\n",
            "\n",
            "  Average training loss: 0.13461\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99023\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    50  of    140.    Elapsed: 0:00:29.\n",
            "  Batch   100  of    140.    Elapsed: 0:00:59.\n",
            "\n",
            "  Average training loss: 0.06754\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99219\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    50  of    140.    Elapsed: 0:00:29.\n",
            "  Batch   100  of    140.    Elapsed: 0:00:58.\n",
            "\n",
            "  Average training loss: 0.03857\n",
            "  Training epcoh took: 0:01:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99023\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "PrwKmcCoKKUe",
        "outputId": "5bf86f7c-df84-49c4-c839-7d299d2d42bb"
      },
      "source": [
        "# loss를 시각화합니다. \n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHul74yIfQoy"
      },
      "source": [
        "## Inference "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA4XL7YvgMZh"
      },
      "source": [
        "### 1. Test set Preprocess \n",
        "* inference 과정을 위해, test set을 input 형식에 맞추어 재가공합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQazUSZogUyH"
      },
      "source": [
        "# load test data\n",
        "sentences = [\"[CLS] \" + query + \" [SEP]\" for query in query_data_test]\n",
        "labels = intent_data_label_test\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDmIp8qGgaM_"
      },
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbopWd1hgchW"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCb7BHL-geoT"
      },
      "source": [
        "# to tensor\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biiYBeiSQ8_-"
      },
      "source": [
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jos5m9k0gq-F"
      },
      "source": [
        "### 2. Evaluation \n",
        "* test set을 통해 모델이 적절한지 평가합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqBq4dAGgsww",
        "outputId": "bebcea62-c0df-442b-d239-25290bc90f6f"
      },
      "source": [
        "# ========================================\n",
        "#                Predict\n",
        "# ========================================\n",
        "\n",
        "print(\"\")\n",
        "print(\"Test...\")\n",
        "\n",
        "# 시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# evaluation \n",
        "model.eval()\n",
        "\n",
        "# tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# DataLoader 에서 batch 만큼 반복하여 가져옵니다. \n",
        "for batch in prediction_dataloader:\n",
        "    \n",
        "    # batch를 GPU에 올립니다. \n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # batch에서 데이터를 추출합니다. \n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # evaluation 단계 : gradient 업데이트 하지 않습니다. \n",
        "    with torch.no_grad():     \n",
        "        # Forward \n",
        "        logits = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # 예측값과 실제값을 저장합니다. \n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "    \n",
        "print(\"\")\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\n",
        "print(\"Test complete!\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test...\n",
            "\n",
            "Test took: 0:00:04\n",
            "Test complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnH99AUYizLs",
        "outputId": "738aea44-21f3-4bef-e5bd-9a27521a7484"
      },
      "source": [
        "# 성능 평가 : Matthew's correlation coefficient\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  matthews = matthews_corrcoef(true_labels[i],\n",
        "                 np.argmax(predictions[i], axis=1).flatten())\n",
        "  matthews_set.append(matthews)\n",
        "\n",
        "# Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "matthews_corrcoef(flat_true_labels, flat_predictions)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9447790903474139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t_53rjikD0W"
      },
      "source": [
        "### 3. Inference\n",
        "* 학습한 결과를 통해, 새로운 문장이 들어왔을 때의 결과를 추론합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOrvZKfVm0VL"
      },
      "source": [
        "label_index = pd.DataFrame({'intent' : intent_data_train, 'label' : intent_data_label_train})\n",
        "\n",
        "df_index_small = pd.DataFrame(columns=['intent', 'label'])\n",
        "j = 0\n",
        "for i in label_index.intent.unique():\n",
        "    df_index_small.loc[j] = label_index[label_index.intent==i].iloc[0]\n",
        "    j = j+1"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "1SQ_VM18nGL2",
        "outputId": "2e377c43-6b6d-4597-af15-cb1f2107338a"
      },
      "source": [
        "# intent의 label dataframe 생성 \n",
        "df_index_small.sort_values('label', ascending=True)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intent</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>abbreviation</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aircraft</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>aircraft+flight+flight_no</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>airfare</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>airfare+flight_time</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>airline</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>airline+flight_no</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>airport</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>capacity</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>cheapest</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>city</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>distance</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>flight</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>flight+airfare</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>flight_no</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>flight_time</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ground_fare</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ground_service</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ground_service+ground_fare</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>meal</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>quantity</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>restriction</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        intent label\n",
              "8   abbreviation                0   \n",
              "3   aircraft                    1   \n",
              "21  aircraft+flight+flight_no   2   \n",
              "2   airfare                     3   \n",
              "19  airfare+flight_time         5   \n",
              "6   airline                     6   \n",
              "17  airline+flight_no           7   \n",
              "5   airport                     8   \n",
              "13  capacity                    9   \n",
              "20  cheapest                    10  \n",
              "11  city                        11  \n",
              "7   distance                    13  \n",
              "0   flight                      14  \n",
              "14  flight+airfare              15  \n",
              "12  flight_no                   17  \n",
              "1   flight_time                 19  \n",
              "9   ground_fare                 20  \n",
              "4   ground_service              21  \n",
              "18  ground_service+ground_fare  22  \n",
              "15  meal                        23  \n",
              "10  quantity                    24  \n",
              "16  restriction                 25  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLBIpXZ0kFSp"
      },
      "source": [
        "# 입력 데이터 변환\n",
        "def convert_input_data(sentences):\n",
        "\n",
        "    # tokenizing \n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "    MAX_LEN = 128\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    \n",
        "    # padding\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # attention mask \n",
        "    attention_masks = []\n",
        "\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    # to pytorch tensor \n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return inputs, masks"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDLPbIzUnxac"
      },
      "source": [
        "# 문장 테스트\n",
        "def test_sentences(sentences):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # 문장을 입력 데이터로 변환합니다. \n",
        "    inputs, masks = convert_input_data(sentences)\n",
        "\n",
        "    # 데이터를 GPU에 올립니다. \n",
        "    b_input_ids = inputs.to(device)\n",
        "    b_input_mask = masks.to(device)\n",
        "\n",
        "\n",
        "    # inference  \n",
        "    with torch.no_grad():     \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # prediction \n",
        "    logits = outputs.detach().cpu().numpy()\n",
        "\n",
        "    # output \n",
        "    result = df_index_small[df_index_small[\"label\"] == np.argmax(logits)][\"intent\"][0]\n",
        "\n",
        "    print(\"* intent *\")\n",
        "\n",
        "    return result"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "QgOv3rHtoKsc",
        "outputId": "a61f46af-eb77-4c92-d1dd-f185b60e2041"
      },
      "source": [
        "test_sentences(['What is the Cheapest Flight from San Francisco to Boston?'])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* intent *\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'flight'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evB5pzZ9f4_G"
      },
      "source": [
        "## 참고자료\n",
        "* BERT-for-dummies : https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03 \n",
        "* BERT 톺아보기 : http://docs.likejazz.com/bert/"
      ]
    }
  ]
}