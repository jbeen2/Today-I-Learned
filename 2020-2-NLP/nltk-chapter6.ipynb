{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1   Gender Identification\n",
    "In 4 we saw that male and female names have some distinctive characteristics. Names ending in a, e and i are likely to be female, while names ending in k, o, r, s and t are likely to be male. Let's build a classifier to model these differences more precisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Classification: 0.736\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "                 [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(labeled_names)\n",
    "\n",
    "\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]} # 끝자리 하나로 남/여 구분해보기 \n",
    "\n",
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Gender Classification:\", nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2   Choosing The Right Features\n",
    "Selecting relevant features and deciding how to encode them for a learning method can have an enormous impact on the learning method's ability to extract a good model. Much of the interesting work in building a classifier is deciding what features might be relevant, and how we can represent them. Although it's often possible to get decent performance by using a fairly simple and obvious set of features, there are usually significant gains to be had by using carefully constructed features based on a thorough understanding of the task at hand.\n",
    "\n",
    "Typically, feature extractors are built through a process of trial-and-error, guided by intuitions about what information is relevant to the problem. It's common to start with a \"kitchen sink\" approach, including all the features that you can think of, and then checking to see which features actually are helpful. We take this approach for name gender features in 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "def gender_features2(name): # overfitting (?) : last name이랑 first name 모두 보자 \n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    \n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features\n",
    "\n",
    "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once an initial set of features has been chosen, a very productive method for refining the feature set is error analysis. First, we select a development set, containing the corpus data for creating the model. This development set is then subdivided into the training set and the dev-test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error analysis \n",
    "train_names = labeled_names[1500:]\n",
    "devtest_names = labeled_names[500:1500]\n",
    "test_names = labeled_names[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Adel                          \n",
      "correct=female   guess=male     name=Ag                            \n",
      "correct=female   guess=male     name=Alis                          \n",
      "correct=female   guess=male     name=Alison                        \n",
      "correct=female   guess=male     name=Allsun                        \n",
      "correct=female   guess=male     name=Allys                         \n",
      "correct=female   guess=male     name=Alyss                         \n",
      "correct=female   guess=male     name=Angil                         \n",
      "correct=female   guess=male     name=Arabel                        \n",
      "correct=female   guess=male     name=Ardys                         \n",
      "correct=female   guess=male     name=Avis                          \n",
      "correct=female   guess=male     name=Avrit                         \n",
      "correct=female   guess=male     name=Ayn                           \n",
      "correct=female   guess=male     name=Bel                           \n",
      "correct=female   guess=male     name=Bidget                        \n",
      "correct=female   guess=male     name=Birgit                        \n",
      "correct=female   guess=male     name=Blondell                      \n",
      "correct=female   guess=male     name=Brett                         \n",
      "correct=female   guess=male     name=Bridgett                      \n",
      "correct=female   guess=male     name=Brigit                        \n",
      "correct=female   guess=male     name=Brit                          \n",
      "correct=female   guess=male     name=Brittan                       \n",
      "correct=female   guess=male     name=Brooks                        \n",
      "correct=female   guess=male     name=Cameo                         \n",
      "correct=female   guess=male     name=Carlen                        \n",
      "correct=female   guess=male     name=Carolann                      \n",
      "correct=female   guess=male     name=Caroljean                     \n",
      "correct=female   guess=male     name=Carolynn                      \n",
      "correct=female   guess=male     name=Caryn                         \n",
      "correct=female   guess=male     name=Cathyleen                     \n",
      "correct=female   guess=male     name=Charlott                      \n",
      "correct=female   guess=male     name=Charyl                        \n",
      "correct=female   guess=male     name=Clem                          \n",
      "correct=female   guess=male     name=Consuelo                      \n",
      "correct=female   guess=male     name=Coral                         \n",
      "correct=female   guess=male     name=Coriss                        \n",
      "correct=female   guess=male     name=Cristabel                     \n",
      "correct=female   guess=male     name=Crystal                       \n",
      "correct=female   guess=male     name=Daloris                       \n",
      "correct=female   guess=male     name=Damaris                       \n",
      "correct=female   guess=male     name=Danell                        \n",
      "correct=female   guess=male     name=Darb                          \n",
      "correct=female   guess=male     name=Darleen                       \n",
      "correct=female   guess=male     name=Dawn                          \n",
      "correct=female   guess=male     name=Deeann                        \n",
      "correct=female   guess=male     name=Denys                         \n",
      "correct=female   guess=male     name=Doll                          \n",
      "correct=female   guess=male     name=Dyan                          \n",
      "correct=female   guess=male     name=Eilis                         \n",
      "correct=female   guess=male     name=Ellen                         \n",
      "correct=female   guess=male     name=Elyn                          \n",
      "correct=female   guess=male     name=Ethelin                       \n",
      "correct=female   guess=male     name=Farrand                       \n",
      "correct=female   guess=male     name=Gen                           \n",
      "correct=female   guess=male     name=Germain                       \n",
      "correct=female   guess=male     name=Gertrudis                     \n",
      "correct=female   guess=male     name=Gilligan                      \n",
      "correct=female   guess=male     name=Ginger                        \n",
      "correct=female   guess=male     name=Glad                          \n",
      "correct=female   guess=male     name=Gredel                        \n",
      "correct=female   guess=male     name=Gretel                        \n",
      "correct=female   guess=male     name=Grethel                       \n",
      "correct=female   guess=male     name=Hannibal                      \n",
      "correct=female   guess=male     name=Hesther                       \n",
      "correct=female   guess=male     name=Ingeberg                      \n",
      "correct=female   guess=male     name=Jacquelynn                    \n",
      "correct=female   guess=male     name=Jenn                          \n",
      "correct=female   guess=male     name=Jillian                       \n",
      "correct=female   guess=male     name=Jo                            \n",
      "correct=female   guess=male     name=Joannes                       \n",
      "correct=female   guess=male     name=Jocelin                       \n",
      "correct=female   guess=male     name=Joscelin                      \n",
      "correct=female   guess=male     name=Joselyn                       \n",
      "correct=female   guess=male     name=Joslyn                        \n",
      "correct=female   guess=male     name=Jourdan                       \n",
      "correct=female   guess=male     name=Kaitlin                       \n",
      "correct=female   guess=male     name=Karen                         \n",
      "correct=female   guess=male     name=Kat                           \n",
      "correct=female   guess=male     name=Katharyn                      \n",
      "correct=female   guess=male     name=Katheryn                      \n",
      "correct=female   guess=male     name=Koren                         \n",
      "correct=female   guess=male     name=Kristyn                       \n",
      "correct=female   guess=male     name=Laurel                        \n",
      "correct=female   guess=male     name=Lauryn                        \n",
      "correct=female   guess=male     name=Leann                         \n",
      "correct=female   guess=male     name=Linnell                       \n",
      "correct=female   guess=male     name=Loreen                        \n",
      "correct=female   guess=male     name=Lynnet                        \n",
      "correct=female   guess=male     name=Madalyn                       \n",
      "correct=female   guess=male     name=Madelon                       \n",
      "correct=female   guess=male     name=Madlin                        \n",
      "correct=female   guess=male     name=Maegan                        \n",
      "correct=female   guess=male     name=Mag                           \n",
      "correct=female   guess=male     name=Marget                        \n",
      "correct=female   guess=male     name=Marin                         \n",
      "correct=female   guess=male     name=Maris                         \n",
      "correct=female   guess=male     name=Marj                          \n",
      "correct=female   guess=male     name=Maryangelyn                   \n",
      "correct=female   guess=male     name=Meagan                        \n",
      "correct=female   guess=male     name=Michell                       \n",
      "correct=female   guess=male     name=Murial                        \n",
      "correct=female   guess=male     name=Nert                          \n",
      "correct=female   guess=male     name=Nichol                        \n",
      "correct=female   guess=male     name=Noelyn                        \n",
      "correct=female   guess=male     name=Persis                        \n",
      "correct=female   guess=male     name=Phylis                        \n",
      "correct=female   guess=male     name=Raynell                       \n",
      "correct=female   guess=male     name=Robin                         \n",
      "correct=female   guess=male     name=Robinett                      \n",
      "correct=female   guess=male     name=Rosamund                      \n",
      "correct=female   guess=male     name=Rozamond                      \n",
      "correct=female   guess=male     name=Shannon                       \n",
      "correct=female   guess=male     name=Sharon                        \n",
      "correct=female   guess=male     name=Sinead                        \n",
      "correct=female   guess=male     name=Stoddard                      \n",
      "correct=female   guess=male     name=Suellen                       \n",
      "correct=female   guess=male     name=Sydel                         \n",
      "correct=female   guess=male     name=Ted                           \n",
      "correct=female   guess=male     name=Vivian                        \n",
      "correct=female   guess=male     name=Vivien                        \n",
      "correct=female   guess=male     name=Winnifred                     \n",
      "correct=male     guess=female   name=Abe                           \n",
      "correct=male     guess=female   name=Aditya                        \n",
      "correct=male     guess=female   name=Allah                         \n",
      "correct=male     guess=female   name=Alley                         \n",
      "correct=male     guess=female   name=Ambrose                       \n",
      "correct=male     guess=female   name=Anatole                       \n",
      "correct=male     guess=female   name=Andrey                        \n",
      "correct=male     guess=female   name=Archie                        \n",
      "correct=male     guess=female   name=Arie                          \n",
      "correct=male     guess=female   name=Avi                           \n",
      "correct=male     guess=female   name=Baillie                       \n",
      "correct=male     guess=female   name=Barde                         \n",
      "correct=male     guess=female   name=Barnaby                       \n",
      "correct=male     guess=female   name=Barnie                        \n",
      "correct=male     guess=female   name=Bartie                        \n",
      "correct=male     guess=female   name=Barty                         \n",
      "correct=male     guess=female   name=Benjie                        \n",
      "correct=male     guess=female   name=Bernie                        \n",
      "correct=male     guess=female   name=Brinkley                      \n",
      "correct=male     guess=female   name=Bubba                         \n",
      "correct=male     guess=female   name=Carlie                        \n",
      "correct=male     guess=female   name=Chancey                       \n",
      "correct=male     guess=female   name=Chrissy                       \n",
      "correct=male     guess=female   name=Christy                       \n",
      "correct=male     guess=female   name=Clive                         \n",
      "correct=male     guess=female   name=Constantine                   \n",
      "correct=male     guess=female   name=Corrie                        \n",
      "correct=male     guess=female   name=Cy                            \n",
      "correct=male     guess=female   name=Darcy                         \n",
      "correct=male     guess=female   name=Daryle                        \n",
      "correct=male     guess=female   name=Dmitri                        \n",
      "correct=male     guess=female   name=Dougie                        \n",
      "correct=male     guess=female   name=Doyle                         \n",
      "correct=male     guess=female   name=Duffy                         \n",
      "correct=male     guess=female   name=Felice                        \n",
      "correct=male     guess=female   name=Felipe                        \n",
      "correct=male     guess=female   name=Ferdy                         \n",
      "correct=male     guess=female   name=Gabriele                      \n",
      "correct=male     guess=female   name=Garcia                        \n",
      "correct=male     guess=female   name=Garry                         \n",
      "correct=male     guess=female   name=Gary                          \n",
      "correct=male     guess=female   name=Geri                          \n",
      "correct=male     guess=female   name=Gordie                        \n",
      "correct=male     guess=female   name=Graehme                       \n",
      "correct=male     guess=female   name=Graeme                        \n",
      "correct=male     guess=female   name=Granville                     \n",
      "correct=male     guess=female   name=Guy                           \n",
      "correct=male     guess=female   name=Hailey                        \n",
      "correct=male     guess=female   name=Hersch                        \n",
      "correct=male     guess=female   name=Hervey                        \n",
      "correct=male     guess=female   name=Hewe                          \n",
      "correct=male     guess=female   name=Hezekiah                      \n",
      "correct=male     guess=female   name=Holly                         \n",
      "correct=male     guess=female   name=Humphrey                      \n",
      "correct=male     guess=female   name=Huntlee                       \n",
      "correct=male     guess=female   name=Hymie                         \n",
      "correct=male     guess=female   name=Jay                           \n",
      "correct=male     guess=female   name=Jean-Pierre                   \n",
      "correct=male     guess=female   name=Jeramie                       \n",
      "correct=male     guess=female   name=Jeremy                        \n",
      "correct=male     guess=female   name=Jermayne                      \n",
      "correct=male     guess=female   name=Jerri                         \n",
      "correct=male     guess=female   name=Jordy                         \n",
      "correct=male     guess=female   name=Jorge                         \n",
      "correct=male     guess=female   name=Jory                          \n",
      "correct=male     guess=female   name=Kingsly                       \n",
      "correct=male     guess=female   name=Manish                        \n",
      "correct=male     guess=female   name=Marlowe                       \n",
      "correct=male     guess=female   name=Merry                         \n",
      "correct=male     guess=female   name=Mickey                        \n",
      "correct=male     guess=female   name=Moishe                        \n",
      "correct=male     guess=female   name=Monty                         \n",
      "correct=male     guess=female   name=Munroe                        \n",
      "correct=male     guess=female   name=Nealy                         \n",
      "correct=male     guess=female   name=Nevile                        \n",
      "correct=male     guess=female   name=Nickie                        \n",
      "correct=male     guess=female   name=Nikolai                       \n",
      "correct=male     guess=female   name=Noah                          \n",
      "correct=male     guess=female   name=Orville                       \n",
      "correct=male     guess=female   name=Pace                          \n",
      "correct=male     guess=female   name=Partha                        \n",
      "correct=male     guess=female   name=Pasquale                      \n",
      "correct=male     guess=female   name=Patrice                       \n",
      "correct=male     guess=female   name=Pearce                        \n",
      "correct=male     guess=female   name=Penny                         \n",
      "correct=male     guess=female   name=Pepe                          \n",
      "correct=male     guess=female   name=Percy                         \n",
      "correct=male     guess=female   name=Pete                          \n",
      "correct=male     guess=female   name=Prince                        \n",
      "correct=male     guess=female   name=Rabbi                         \n",
      "correct=male     guess=female   name=Randie                        \n",
      "correct=male     guess=female   name=Rice                          \n",
      "correct=male     guess=female   name=Rodrique                      \n",
      "correct=male     guess=female   name=Rolfe                         \n",
      "correct=male     guess=female   name=Roy                           \n",
      "correct=male     guess=female   name=Ruby                          \n",
      "correct=male     guess=female   name=Salomone                      \n",
      "correct=male     guess=female   name=Shea                          \n",
      "correct=male     guess=female   name=Sheffy                        \n",
      "correct=male     guess=female   name=Sherlocke                     \n",
      "correct=male     guess=female   name=Simone                        \n",
      "correct=male     guess=female   name=Skippy                        \n",
      "correct=male     guess=female   name=Spense                        \n",
      "correct=male     guess=female   name=Stanleigh                     \n",
      "correct=male     guess=female   name=Tarrance                      \n",
      "correct=male     guess=female   name=Teddie                        \n",
      "correct=male     guess=female   name=Timmie                        \n",
      "correct=male     guess=female   name=Toddie                        \n",
      "correct=male     guess=female   name=Torre                         \n",
      "correct=male     guess=female   name=Torrey                        \n",
      "correct=male     guess=female   name=Tracey                        \n",
      "correct=male     guess=female   name=Tracie                        \n",
      "correct=male     guess=female   name=Troy                          \n",
      "correct=male     guess=female   name=Tulley                        \n",
      "correct=male     guess=female   name=Tully                         \n",
      "correct=male     guess=female   name=Tye                           \n",
      "correct=male     guess=female   name=Verney                        \n",
      "correct=male     guess=female   name=Waine                         \n",
      "correct=male     guess=female   name=Welby                         \n",
      "correct=male     guess=female   name=Westley                       \n",
      "correct=male     guess=female   name=Willey                        \n",
      "correct=male     guess=female   name=Winny                         \n",
      "correct=male     guess=female   name=Yance                         \n",
      "correct=male     guess=female   name=Yancey                        \n",
      "correct=male     guess=female   name=Yuri                          \n",
      "correct=male     guess=female   name=Zane                          \n",
      "correct=male     guess=female   name=Zedekiah                      \n"
     ]
    }
   ],
   "source": [
    "# error case : 잘못 분류한 경우 \n",
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, name) )\n",
    "        \n",
    "for (tag, guess, name) in sorted(errors):\n",
    "    print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "     return {'suffix1': word[-1:],\n",
    "             'suffix2': word[-2:]} # 끝에 두 자리를 보면 좀 더 나아지지 않을까 .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3   Document Classification\n",
    "In 1, we saw several examples of corpora where documents have been labeled with categories. Using these corpora, we can build classifiers that will automatically tag new documents with appropriate category labels. First, we construct a list of documents, labeled with the appropriate categories. For this example, we've chosen the **Movie Reviews Corpus**, which categorizes each review as positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(c|d) = {P(d|c)P(c) \\over P(d)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words()) # frequency distribution \n",
    "word_features = list(all_words)[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 77717, 'the': 76529, '.': 65876, 'a': 38106, 'and': 35576, 'of': 34123, 'to': 31937, \"'\": 30585, 'is': 25195, 'in': 21822, ...})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Classification: 0.78\n"
     ]
    }
   ],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents] # bag of words \n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Document Classification:\", nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     13.8 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      9.1 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      7.7 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      7.7 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      5.9 : 1.0\n",
      "         contains(awful) = True              neg : pos    =      5.7 : 1.0\n",
      "         contains(flynt) = True              pos : neg    =      5.7 : 1.0\n",
      "        contains(wasted) = True              neg : pos    =      5.7 : 1.0\n",
      "          contains(lame) = True              neg : pos    =      5.5 : 1.0\n",
      "        contains(poorly) = True              neg : pos    =      5.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4   Part-of-Speech Tagging\n",
    "In 5. we built a regular expression tagger that chooses a part-of-speech tag for a word by looking at the internal make-up of the word. However, this regular expression tagger had to be hand-crafted. Instead, we can train a classifier to work out which suffixes are most informative. Let's begin by finding out what the most common suffixes are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown # 카테고리 별로 코퍼스를 나누어 놓음  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_fdist = nltk.FreqDist()\n",
    "\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    suffix_fdist[word[-1:]] += 1\n",
    "    suffix_fdist[word[-2:]] += 1\n",
    "    suffix_fdist[word[-3:]] += 1\n",
    "    \n",
    "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(word):\n",
    "    features = {}\n",
    "    for suffix in common_suffixes:\n",
    "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tagging: 0.6270512182993535\n"
     ]
    }
   ],
   "source": [
    "tagged_words = brown.tagged_words(categories='news')\n",
    "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "print(\"POS Tagging:\", nltk.classify.accuracy(classifier,test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('Grand', 'JJ-TL'),\n",
       " ('Jury', 'NN-TL'),\n",
       " ('said', 'VBD'),\n",
       " ('Friday', 'NR'),\n",
       " ('an', 'AT'),\n",
       " ('investigation', 'NN'),\n",
       " ('of', 'IN')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5   Exploiting Context\n",
    "By augmenting the feature extraction function, we could modify this part-of-speech tagger to leverage a variety of other word-internal features, such as the length of the word, the number of syllables it contains, or its prefix. However, as long as the feature extractor just looks at the target word, we have no way to add features that depend on the context that the word appears in. But contextual features often provide powerful clues about the correct tag — for example, when tagging the word \"fly,\" knowing that the previous word is \"a\" will allow us to determine that it is functioning as a noun, not a verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i): \n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:]}\n",
    "    \n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features(brown.sents()[0], 8)\n",
    "\n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "featuresets = []\n",
    "for tagged_sent in tagged_sents:\n",
    "    untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "    for i, (word, tag) in enumerate(tagged_sent):\n",
    "        featuresets.append( (pos_features(untagged_sent, i), tag) )\n",
    "\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6   Sequence Classification\n",
    "In order to capture the dependencies between related classification tasks, we can use joint classifier models, which choose an appropriate labeling for a collection of related inputs. In the case of part-of-speech tagging, a variety of different sequence classifier models can be used to jointly choose part-of-speech tags for all the words in a given sentence.\n",
    "\n",
    "One sequence classification strategy, known as consecutive classification or greedy sequence classification, is to find the most likely class label for the first input, then to use that answer to help find the best label for the next input. The process can then be repeated until all of the inputs have been labeled. This is the approach that was taken by the bigram tagger from 5, which began by choosing a part-of-speech tag for the first word in the sentence, and then chose the tag for each subsequent word based on the word itself and the predicted tag for the previous word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i, history):\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:]}\n",
    "    \n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "        features[\"prev-tag\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "        features[\"prev-tag\"] = history[i-1]\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consecutive POS Tagger: 0.7980528511821975\n"
     ]
    }
   ],
   "source": [
    "class ConsecutivePosTagger(nltk.TaggerI):\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = pos_features(untagged_sent, i, history)\n",
    "                train_set.append( (featureset, tag) )\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        \n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = pos_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)\n",
    "    \n",
    "    \n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(tagged_sents) * 0.1)\n",
    "train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n",
    "tagger = ConsecutivePosTagger(train_sents)\n",
    "print(\"Consecutive POS Tagger:\", tagger.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1   Sentence Segmentation\n",
    "Sentence segmentation can be viewed as a classification task for punctuation: whenever we encounter a symbol that could possibly end a sentence, such as a period or a question mark, we have to decide whether it terminates the preceding sentence.\n",
    "\n",
    "The first step is to obtain some data that has already been segmented into sentences and convert it into a form that is suitable for extracting features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Segmentation: 0.936026936026936\n"
     ]
    }
   ],
   "source": [
    "def segment_sentences(words):\n",
    "    start = 0\n",
    "    sents = []\n",
    "    for i, word in enumerate(words):\n",
    "        if word in '.?!' and classifier.classify(punct_features(words, i)) == True:\n",
    "            sents.append(words[start:i+1])\n",
    "            start = i+1\n",
    "    if start < len(words):\n",
    "        sents.append(words[start:])\n",
    "    return sents\n",
    "\n",
    "sents = nltk.corpus.treebank_raw.sents()\n",
    "tokens = []\n",
    "boundaries = set()\n",
    "offset = 0\n",
    "\n",
    "for sent in sents:\n",
    "    tokens.extend(sent)\n",
    "    offset += len(sent)\n",
    "    boundaries.add(offset-1)\n",
    "    \n",
    "def punct_features(tokens, i):\n",
    "    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
    "            'prev-word': tokens[i-1].lower(),\n",
    "            'punct': tokens[i],\n",
    "            'prev-word-is-one-char': len(tokens[i-1]) == 1}\n",
    "\n",
    "featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
    "                for i in range(1, len(tokens)-1) if tokens[i] in '.?!']\n",
    "\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)\n",
    "print(\"Sentence Segmentation:\", nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2   Identifying Dialogue Act Types\n",
    "When processing dialogue, it can be useful to think of utterances as a type of action performed by the speaker. This interpretation is most straightforward for performative statements such as \"I forgive you\" or \"I bet you can't climb that hill.\" But greetings, questions, answers, assertions, and clarifications can all be thought of as types of speech-based actions. Recognizing the dialogue acts underlying the utterances in a dialogue can be an important first step in understanding the conversation.\n",
    "\n",
    "The NPS Chat Corpus, which was demonstrated in 1, consists of over 10,000 posts from instant messaging sessions. These posts have all been labeled with one of 15 dialogue act types, such as \"Statement,\" \"Emotion,\" \"ynQuestion\", and \"Continuer.\" We can therefore use this data to build a classifier that can identify the dialogue act types for new instant messaging posts. The first step is to extract the basic messaging data. We will call xml_posts() to get a data structure representing the XML annotation for each post:# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialog Act Type: 0.668\n"
     ]
    }
   ],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()[:10000]\n",
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "            features['contains({})'.format(word.lower())] = True\n",
    "    return features\n",
    "\n",
    "featuresets = [(dialogue_act_features(post.text), post.get('class')) for post in posts]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Dialog Act Type:\", nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3   Recognizing Textual Entailment\n",
    "Recognizing textual entailment (RTE) is the task of determining whether a given piece of text T entails another text called the \"hypothesis\" (as already discussed in 5). To date, there have been four RTE Challenges, where shared development and test data is made available to competing teams. Here are a couple of examples of text/hypothesis pairs from the Challenge 3 development dataset. The label True indicates that the entailment holds, and False, that it fails to hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTE Recognition: 0.4625\n"
     ]
    }
   ],
   "source": [
    "rtepairs = nltk.corpus.rte.pairs(['rte3_dev.xml'])\n",
    "def rte_features(rtepair):\n",
    "    extractor = nltk.RTEFeatureExtractor(rtepair)\n",
    "    features = {}\n",
    "    features['word_overlap'] = len(extractor.overlap('word'))\n",
    "    features['word_hyp_extra'] = len(extractor.hyp_extra('word'))\n",
    "    features['ne_overlap'] = len(extractor.overlap('ne'))\n",
    "    features['ne_hyp_extra'] = len(extractor.hyp_extra('ne'))\n",
    "    return features\n",
    "\n",
    "featuresets = [(rte_features(rtepair), rtepair.value) for rtepair in rtepairs]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"RTE Recognition:\", nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK에서 scikit-learn Wrapper 활용하기\n",
    "* https://youtu.be/nla4C-VYNEU \n",
    "* https://www.python-course.eu/neural_networks_with_scikit.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNH_classifier = SklearnClassifier(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB Accuracy: 82.0\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "training_set = featuresets[:1900]\n",
    "testing_set = featuresets[1900:]\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB Accuracy:\", (nltk.classify.accuracy(MNB_classifier,testing_set))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
